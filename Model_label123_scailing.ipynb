{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f858c68",
   "metadata": {},
   "source": [
    "1. 라이브러리 및 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097a339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062a3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('C:/Users/zz325/PycharmProjects/2020742043/Datamining/1.Training/원천데이터/2.수면/train_sleep.csv')\n",
    "train_label = pd.read_csv('C:/Users/zz325/PycharmProjects/2020742043/Datamining/1.Training/라벨링데이터/2.수면/training_label.csv')\n",
    "test = pd.read_csv('C:/Users/zz325/PycharmProjects/2020742043/Datamining/2.Validation/원천데이터/2.수면/val_sleep.csv')\n",
    "test_label = pd.read_csv('C:/Users/zz325/PycharmProjects/2020742043/Datamining/2.Validation/라벨링데이터/2.수면/val_label.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90498639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9705, 36)\n",
      "(141, 2)\n",
      "(2478, 36)\n",
      "(33, 2)\n",
      "DIAG_NM\n",
      "CN     85\n",
      "MCI    47\n",
      "Dem     9\n",
      "Name: count, dtype: int64\n",
      "DIAG_NM\n",
      "CN     26\n",
      "MCI     4\n",
      "Dem     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train data 연구 참여자 수: 141 = 85(CN) + 47(MCI) + Dem(9)\n",
    "# test data 연구 참여자 수: 33 = 26(CN) + MCI(4) + Dem(3)\n",
    "\n",
    "print(train.shape)\n",
    "print(train_label.shape)\n",
    "print(test.shape)\n",
    "print(test_label.shape)\n",
    "print(train_label['DIAG_NM'].value_counts())\n",
    "print(test_label['DIAG_NM'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1e184c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sleep_awake</th>\n",
       "      <th>sleep_breath_average</th>\n",
       "      <th>sleep_deep</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>sleep_efficiency</th>\n",
       "      <th>sleep_hr_average</th>\n",
       "      <th>sleep_hr_lowest</th>\n",
       "      <th>sleep_is_longest</th>\n",
       "      <th>sleep_light</th>\n",
       "      <th>sleep_midpoint_at_delta</th>\n",
       "      <th>...</th>\n",
       "      <th>sleep_score_disturbances</th>\n",
       "      <th>sleep_score_efficiency</th>\n",
       "      <th>sleep_score_latency</th>\n",
       "      <th>sleep_score_rem</th>\n",
       "      <th>sleep_score_total</th>\n",
       "      <th>sleep_temperature_delta</th>\n",
       "      <th>sleep_temperature_deviation</th>\n",
       "      <th>sleep_total</th>\n",
       "      <th>target</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1860</td>\n",
       "      <td>15.875</td>\n",
       "      <td>5640</td>\n",
       "      <td>24480</td>\n",
       "      <td>92</td>\n",
       "      <td>59.63</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>11670</td>\n",
       "      <td>10776</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>97</td>\n",
       "      <td>94</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>22620</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1860</td>\n",
       "      <td>16.000</td>\n",
       "      <td>9660</td>\n",
       "      <td>31200</td>\n",
       "      <td>94</td>\n",
       "      <td>60.74</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>11250</td>\n",
       "      <td>8204</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>29340</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3210</td>\n",
       "      <td>15.625</td>\n",
       "      <td>7230</td>\n",
       "      <td>30420</td>\n",
       "      <td>89</td>\n",
       "      <td>61.25</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>14100</td>\n",
       "      <td>8574</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>27210</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1890</td>\n",
       "      <td>16.250</td>\n",
       "      <td>6690</td>\n",
       "      <td>28980</td>\n",
       "      <td>93</td>\n",
       "      <td>60.26</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>15750</td>\n",
       "      <td>9217</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>27090</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200</td>\n",
       "      <td>15.875</td>\n",
       "      <td>4980</td>\n",
       "      <td>30180</td>\n",
       "      <td>96</td>\n",
       "      <td>60.71</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>18600</td>\n",
       "      <td>8349</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>28980</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>9480</td>\n",
       "      <td>15.625</td>\n",
       "      <td>3720</td>\n",
       "      <td>46200</td>\n",
       "      <td>79</td>\n",
       "      <td>66.78</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>20580</td>\n",
       "      <td>6719</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>36720</td>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>8280</td>\n",
       "      <td>15.000</td>\n",
       "      <td>3480</td>\n",
       "      <td>38280</td>\n",
       "      <td>78</td>\n",
       "      <td>70.26</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>18030</td>\n",
       "      <td>3181</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>2580</td>\n",
       "      <td>17.625</td>\n",
       "      <td>4890</td>\n",
       "      <td>26940</td>\n",
       "      <td>90</td>\n",
       "      <td>69.55</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>13470</td>\n",
       "      <td>10501</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>24360</td>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9703</th>\n",
       "      <td>8940</td>\n",
       "      <td>16.625</td>\n",
       "      <td>4470</td>\n",
       "      <td>40860</td>\n",
       "      <td>78</td>\n",
       "      <td>70.85</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>18420</td>\n",
       "      <td>5415</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>31920</td>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>8850</td>\n",
       "      <td>17.000</td>\n",
       "      <td>4560</td>\n",
       "      <td>36720</td>\n",
       "      <td>76</td>\n",
       "      <td>70.62</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>16470</td>\n",
       "      <td>11039</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.96</td>\n",
       "      <td>27870</td>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9705 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sleep_awake  sleep_breath_average  sleep_deep  sleep_duration  \\\n",
       "0            1860                15.875        5640           24480   \n",
       "1            1860                16.000        9660           31200   \n",
       "2            3210                15.625        7230           30420   \n",
       "3            1890                16.250        6690           28980   \n",
       "4            1200                15.875        4980           30180   \n",
       "...           ...                   ...         ...             ...   \n",
       "9700         9480                15.625        3720           46200   \n",
       "9701         8280                15.000        3480           38280   \n",
       "9702         2580                17.625        4890           26940   \n",
       "9703         8940                16.625        4470           40860   \n",
       "9704         8850                17.000        4560           36720   \n",
       "\n",
       "      sleep_efficiency  sleep_hr_average  sleep_hr_lowest  sleep_is_longest  \\\n",
       "0                   92             59.63               54                 1   \n",
       "1                   94             60.74               53                 1   \n",
       "2                   89             61.25               53                 1   \n",
       "3                   93             60.26               53                 1   \n",
       "4                   96             60.71               55                 1   \n",
       "...                ...               ...              ...               ...   \n",
       "9700                79             66.78               60                 1   \n",
       "9701                78             70.26               62                 1   \n",
       "9702                90             69.55               63                 1   \n",
       "9703                78             70.85               63                 1   \n",
       "9704                76             70.62               65                 1   \n",
       "\n",
       "      sleep_light  sleep_midpoint_at_delta  ...  sleep_score_disturbances  \\\n",
       "0           11670                    10776  ...                        79   \n",
       "1           11250                     8204  ...                        80   \n",
       "2           14100                     8574  ...                        79   \n",
       "3           15750                     9217  ...                        81   \n",
       "4           18600                     8349  ...                        84   \n",
       "...           ...                      ...  ...                       ...   \n",
       "9700        20580                     6719  ...                        56   \n",
       "9701        18030                     3181  ...                        62   \n",
       "9702        13470                    10501  ...                        60   \n",
       "9703        18420                     5415  ...                        63   \n",
       "9704        16470                    11039  ...                        62   \n",
       "\n",
       "      sleep_score_efficiency  sleep_score_latency  sleep_score_rem  \\\n",
       "0                         97                   94               72   \n",
       "1                         99                   99               99   \n",
       "2                         95                   97               79   \n",
       "3                         99                   91               63   \n",
       "4                        100                   72               73   \n",
       "...                      ...                  ...              ...   \n",
       "9700                      72                   94              100   \n",
       "9701                      67                   99               99   \n",
       "9702                      96                   72               90   \n",
       "9703                      67                   97              100   \n",
       "9704                      62                   99               96   \n",
       "\n",
       "      sleep_score_total  sleep_temperature_delta  sleep_temperature_deviation  \\\n",
       "0                    61                    -0.13                        -0.13   \n",
       "1                    88                     0.11                         0.11   \n",
       "2                    79                    -0.10                        -0.10   \n",
       "3                    79                     0.13                         0.13   \n",
       "4                    86                    -0.41                        -0.41   \n",
       "...                 ...                      ...                          ...   \n",
       "9700                100                     0.41                         0.41   \n",
       "9701                 96                     0.07                         0.07   \n",
       "9702                 74                    -0.14                        -0.14   \n",
       "9703                 99                     0.25                         0.25   \n",
       "9704                 89                     1.96                         1.96   \n",
       "\n",
       "      sleep_total  target  number  \n",
       "0           22620       1       5  \n",
       "1           29340       1       5  \n",
       "2           27210       1       5  \n",
       "3           27090       1       5  \n",
       "4           28980       1       5  \n",
       "...           ...     ...     ...  \n",
       "9700        36720       3     341  \n",
       "9701        30000       3     341  \n",
       "9702        24360       3     341  \n",
       "9703        31920       3     341  \n",
       "9704        27870       3     341  \n",
       "\n",
       "[9705 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(train, label):\n",
    "    drop_cols = train.describe(include = 'O').columns[1:]\n",
    "    train = train.drop(drop_cols, axis = 1)\n",
    "    data = train.groupby('EMAIL').mean().reset_index()\n",
    "    labeling = dict(np.array(label))\n",
    "\n",
    "    data['target'] = data['EMAIL'].map(labeling)\n",
    "    train['target'] = train['EMAIL'].map(labeling)\n",
    "\n",
    "    # target 변수 numerical data로 변환\n",
    "    target_dict = {\"CN\": 1, \"MCI\": 2, \"Dem\": 3}\n",
    "    data['target'] = data['target'].map(target_dict)\n",
    "    data = data.sort_values(by=['target','EMAIL'], ascending=[True,True])\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    train['target'] = train['target'].map(target_dict)\n",
    "    train = train.sort_values(by=['target','EMAIL'], ascending=[True,True])\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    # Step 1: 'number' 열을 생성 (EMAIL에서 숫자만 추출)\n",
    "    data['number'] = data['EMAIL'].str.extract(r'(?<=nia\\+)(\\d+)', expand=False).astype(int)\n",
    "    train['number'] = train['EMAIL'].str.extract(r'(?<=nia\\+)(\\d+)', expand=False).astype(int)\n",
    "\n",
    "    # Step 2: EMAIL 열 삭제\n",
    "    data.drop(columns=['EMAIL'], inplace=True)\n",
    "    train.drop(columns=['EMAIL'], inplace=True)\n",
    "\n",
    "    return data, train\n",
    "\n",
    "train_mean, train_all = preprocessing(train, train_label)\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e335df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(train_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21d66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_by_pvalue(df):\n",
    "    independent_vars = list(df.columns)\n",
    "\n",
    "    anova_results = {}\n",
    "\n",
    "    for var in independent_vars:\n",
    "        group0 = df[df['target'] == 1][var]\n",
    "        group1 = df[df['target'] == 2][var]\n",
    "        group2 = df[df['target'] == 3][var]\n",
    "    \n",
    "        f_val, p_val = stats.f_oneway(group0, group1, group2)\n",
    "        anova_results[var] = p_val\n",
    "\n",
    "    sorted_vars = sorted(anova_results, key=anova_results.get)\n",
    "\n",
    "    significant_vars = [var for var in sorted_vars if anova_results[var] < 0.05]\n",
    "\n",
    "    print(\"유의미한 변수들:\", significant_vars)\n",
    "    print(len(significant_vars))\n",
    "\n",
    "    return significant_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6971530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유의미한 변수들: ['target', 'number', 'sleep_light', 'sleep_restless', 'sleep_midpoint_time', 'sleep_duration', 'sleep_total', 'sleep_score_deep', 'sleep_score_alignment', 'sleep_awake', 'sleep_deep', 'sleep_score_total', 'sleep_onset_latency', 'sleep_midpoint_at_delta', 'sleep_score_latency', 'sleep_breath_average', 'sleep_hr_lowest', 'sleep_score_efficiency', 'sleep_efficiency', 'sleep_rem', 'sleep_score_disturbances', 'sleep_hr_average', 'sleep_period_id', 'sleep_score_rem', 'sleep_rmssd', 'sleep_temperature_delta', 'sleep_temperature_deviation']\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\datamining\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: ConstantInputWarning: Each of the input arrays is constant; the F statistic is not defined or infinite\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['target',\n",
       " 'number',\n",
       " 'sleep_light',\n",
       " 'sleep_restless',\n",
       " 'sleep_midpoint_time',\n",
       " 'sleep_duration',\n",
       " 'sleep_total',\n",
       " 'sleep_score_deep',\n",
       " 'sleep_score_alignment',\n",
       " 'sleep_awake',\n",
       " 'sleep_deep',\n",
       " 'sleep_score_total',\n",
       " 'sleep_onset_latency',\n",
       " 'sleep_midpoint_at_delta',\n",
       " 'sleep_score_latency',\n",
       " 'sleep_breath_average',\n",
       " 'sleep_hr_lowest',\n",
       " 'sleep_score_efficiency',\n",
       " 'sleep_efficiency',\n",
       " 'sleep_rem',\n",
       " 'sleep_score_disturbances',\n",
       " 'sleep_hr_average',\n",
       " 'sleep_period_id',\n",
       " 'sleep_score_rem',\n",
       " 'sleep_rmssd',\n",
       " 'sleep_temperature_delta',\n",
       " 'sleep_temperature_deviation']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_feature_all = train_all\n",
    "feature_by_pvalue(data_for_feature_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0da9c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유의미한 변수들: ['target', 'number', 'sleep_light', 'sleep_score_latency', 'sleep_midpoint_time', 'sleep_duration', 'sleep_onset_latency', 'sleep_restless', 'sleep_score_alignment', 'sleep_total', 'sleep_score_deep', 'sleep_awake']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "data_for_feature_mean = train_mean\n",
    "feature = feature_by_pvalue(data_for_feature_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5cef6",
   "metadata": {},
   "source": [
    "모델적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4cd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = train_mean\n",
    "X_mean.drop(columns=['number'], inplace=True)\n",
    "X_mean_target = X_mean['target']\n",
    "X_mean.drop(columns=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6477cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X_mean.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe92d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant value list에 number와 target이 포함되어 있어 삭제\n",
    "feature.remove('number')\n",
    "feature.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7b4c207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sleep_light</th>\n",
       "      <th>sleep_score_latency</th>\n",
       "      <th>sleep_midpoint_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>sleep_onset_latency</th>\n",
       "      <th>sleep_restless</th>\n",
       "      <th>sleep_score_alignment</th>\n",
       "      <th>sleep_total</th>\n",
       "      <th>sleep_score_deep</th>\n",
       "      <th>sleep_awake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16303.539823</td>\n",
       "      <td>83.973451</td>\n",
       "      <td>15127.699115</td>\n",
       "      <td>30115.752212</td>\n",
       "      <td>672.212389</td>\n",
       "      <td>29.300885</td>\n",
       "      <td>86.849558</td>\n",
       "      <td>28060.088496</td>\n",
       "      <td>89.345133</td>\n",
       "      <td>2055.663717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14088.000000</td>\n",
       "      <td>74.800000</td>\n",
       "      <td>14404.285714</td>\n",
       "      <td>28422.857143</td>\n",
       "      <td>578.571429</td>\n",
       "      <td>33.571429</td>\n",
       "      <td>89.028571</td>\n",
       "      <td>23275.714286</td>\n",
       "      <td>96.542857</td>\n",
       "      <td>5147.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12606.891892</td>\n",
       "      <td>79.905405</td>\n",
       "      <td>13722.972973</td>\n",
       "      <td>27224.594595</td>\n",
       "      <td>528.243243</td>\n",
       "      <td>32.202703</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>21789.324324</td>\n",
       "      <td>99.081081</td>\n",
       "      <td>5435.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14666.202532</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>17314.556962</td>\n",
       "      <td>34593.417722</td>\n",
       "      <td>817.974684</td>\n",
       "      <td>29.696203</td>\n",
       "      <td>95.430380</td>\n",
       "      <td>25923.037975</td>\n",
       "      <td>92.063291</td>\n",
       "      <td>8670.379747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18325.890411</td>\n",
       "      <td>83.945205</td>\n",
       "      <td>14871.780822</td>\n",
       "      <td>30269.589041</td>\n",
       "      <td>866.712329</td>\n",
       "      <td>43.602740</td>\n",
       "      <td>99.616438</td>\n",
       "      <td>24827.671233</td>\n",
       "      <td>96.904110</td>\n",
       "      <td>5441.917808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>14092.500000</td>\n",
       "      <td>81.931818</td>\n",
       "      <td>14036.590909</td>\n",
       "      <td>26896.363636</td>\n",
       "      <td>991.363636</td>\n",
       "      <td>51.931818</td>\n",
       "      <td>89.704545</td>\n",
       "      <td>19431.136364</td>\n",
       "      <td>56.909091</td>\n",
       "      <td>7465.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>19578.620690</td>\n",
       "      <td>68.609195</td>\n",
       "      <td>18986.896552</td>\n",
       "      <td>36944.827586</td>\n",
       "      <td>1412.413793</td>\n",
       "      <td>27.850575</td>\n",
       "      <td>99.942529</td>\n",
       "      <td>32936.206897</td>\n",
       "      <td>96.919540</td>\n",
       "      <td>4008.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>20261.756757</td>\n",
       "      <td>72.878378</td>\n",
       "      <td>15657.972973</td>\n",
       "      <td>31551.081081</td>\n",
       "      <td>459.729730</td>\n",
       "      <td>46.729730</td>\n",
       "      <td>89.216216</td>\n",
       "      <td>27824.189189</td>\n",
       "      <td>48.081081</td>\n",
       "      <td>3726.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>14174.262295</td>\n",
       "      <td>81.983607</td>\n",
       "      <td>12480.491803</td>\n",
       "      <td>24405.245902</td>\n",
       "      <td>641.311475</td>\n",
       "      <td>41.360656</td>\n",
       "      <td>97.737705</td>\n",
       "      <td>21195.245902</td>\n",
       "      <td>94.377049</td>\n",
       "      <td>3210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>17169.411765</td>\n",
       "      <td>76.490196</td>\n",
       "      <td>17993.529412</td>\n",
       "      <td>35783.529412</td>\n",
       "      <td>968.823529</td>\n",
       "      <td>39.352941</td>\n",
       "      <td>99.686275</td>\n",
       "      <td>28053.529412</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>7730.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sleep_light  sleep_score_latency  sleep_midpoint_time  sleep_duration  \\\n",
       "0    16303.539823            83.973451         15127.699115    30115.752212   \n",
       "1    14088.000000            74.800000         14404.285714    28422.857143   \n",
       "2    12606.891892            79.905405         13722.972973    27224.594595   \n",
       "3    14666.202532            84.000000         17314.556962    34593.417722   \n",
       "4    18325.890411            83.945205         14871.780822    30269.589041   \n",
       "..            ...                  ...                  ...             ...   \n",
       "136  14092.500000            81.931818         14036.590909    26896.363636   \n",
       "137  19578.620690            68.609195         18986.896552    36944.827586   \n",
       "138  20261.756757            72.878378         15657.972973    31551.081081   \n",
       "139  14174.262295            81.983607         12480.491803    24405.245902   \n",
       "140  17169.411765            76.490196         17993.529412    35783.529412   \n",
       "\n",
       "     sleep_onset_latency  sleep_restless  sleep_score_alignment   sleep_total  \\\n",
       "0             672.212389       29.300885              86.849558  28060.088496   \n",
       "1             578.571429       33.571429              89.028571  23275.714286   \n",
       "2             528.243243       32.202703              89.500000  21789.324324   \n",
       "3             817.974684       29.696203              95.430380  25923.037975   \n",
       "4             866.712329       43.602740              99.616438  24827.671233   \n",
       "..                   ...             ...                    ...           ...   \n",
       "136           991.363636       51.931818              89.704545  19431.136364   \n",
       "137          1412.413793       27.850575              99.942529  32936.206897   \n",
       "138           459.729730       46.729730              89.216216  27824.189189   \n",
       "139           641.311475       41.360656              97.737705  21195.245902   \n",
       "140           968.823529       39.352941              99.686275  28053.529412   \n",
       "\n",
       "     sleep_score_deep  sleep_awake  \n",
       "0           89.345133  2055.663717  \n",
       "1           96.542857  5147.142857  \n",
       "2           99.081081  5435.270270  \n",
       "3           92.063291  8670.379747  \n",
       "4           96.904110  5441.917808  \n",
       "..                ...          ...  \n",
       "136         56.909091  7465.227273  \n",
       "137         96.919540  4008.620690  \n",
       "138         48.081081  3726.891892  \n",
       "139         94.377049  3210.000000  \n",
       "140         80.666667  7730.000000  \n",
       "\n",
       "[141 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_logit = X_mean[feature].copy()\n",
    "data_for_logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ae5e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 로지스틱 회귀 구현\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DementiaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DementiaNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(data_for_logit)\n",
    "\n",
    "x = torch.tensor(X_scaled).float()\n",
    "y = torch.tensor(X_mean_target.values - 1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e035ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DementiaNet()\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "los = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1 avg loss; 0.0743\n",
      "        acc.;    0.2624\n",
      "epoch   2 avg loss; 0.0635\n",
      "        acc.;    0.6028\n",
      "epoch   3 avg loss; 0.0598\n",
      "        acc.;    0.6028\n",
      "epoch   4 avg loss; 0.0580\n",
      "        acc.;    0.6028\n",
      "epoch   5 avg loss; 0.0569\n",
      "        acc.;    0.6028\n",
      "epoch   6 avg loss; 0.0563\n",
      "        acc.;    0.6028\n",
      "epoch   7 avg loss; 0.0559\n",
      "        acc.;    0.6028\n",
      "epoch   8 avg loss; 0.0555\n",
      "        acc.;    0.6028\n",
      "epoch   9 avg loss; 0.0553\n",
      "        acc.;    0.6028\n",
      "epoch  10 avg loss; 0.0550\n",
      "        acc.;    0.6028\n",
      "epoch  11 avg loss; 0.0547\n",
      "        acc.;    0.6028\n",
      "epoch  12 avg loss; 0.0545\n",
      "        acc.;    0.6028\n",
      "epoch  13 avg loss; 0.0542\n",
      "        acc.;    0.6028\n",
      "epoch  14 avg loss; 0.0539\n",
      "        acc.;    0.6028\n",
      "epoch  15 avg loss; 0.0537\n",
      "        acc.;    0.6028\n",
      "epoch  16 avg loss; 0.0534\n",
      "        acc.;    0.6028\n",
      "epoch  17 avg loss; 0.0532\n",
      "        acc.;    0.6028\n",
      "epoch  18 avg loss; 0.0530\n",
      "        acc.;    0.6028\n",
      "epoch  19 avg loss; 0.0528\n",
      "        acc.;    0.6028\n",
      "epoch  20 avg loss; 0.0526\n",
      "        acc.;    0.6028\n",
      "done\n",
      "Final accuracy: 0.6028\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    " \n",
    "bs = 16\n",
    "epoch = 20\n",
    "\n",
    "for e in range(1,epoch + 1):\n",
    "    eloss = defaultdict(lambda: [])\n",
    "    for idx in range(0,len(x),bs):\n",
    "        opt.zero_grad()\n",
    "        p = net(x[idx:idx+bs])\n",
    "        loss = los(p, y[idx:idx+bs])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # keep track of some summary statistics\n",
    "        eloss['loss'].append(loss.item())\n",
    "        eloss['n'].append(x[idx:idx+bs].size(0))\n",
    "        eloss['corr'].append(sum(p.max(axis=1)[1] == y[idx:idx+bs]))\n",
    "    print(f'epoch {e:3d} avg loss; {sum(eloss[\"loss\"])/sum(eloss[\"n\"]):.4f}')\n",
    "    print(f'        acc.;    {sum(eloss[\"corr\"])/sum(eloss[\"n\"]):.4f}')\n",
    "print(\"done\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    final_accuracy = (net(x).argmax(dim=1) == y).sum().item() / len(y)\n",
    "print(f\"Final accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a97980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7910\n",
      "Test Loss: 0.7390\n"
     ]
    }
   ],
   "source": [
    "_, test_mean = preprocessing(test, test_label)\n",
    "\n",
    "tmp_mean_target = test_mean['target']\n",
    "\n",
    "tmp_test = test_mean[feature].copy()\n",
    "\n",
    "test_X_scaled = scaler.transform(tmp_test)\n",
    "test_x = torch.tensor(test_X_scaled).float()\n",
    "test_y = torch.tensor(tmp_mean_target.values - 1).long()\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = net(test_x)\n",
    "    predicted_labels = predictions.max(dim=1)[1]\n",
    "    \n",
    "    accuracy = (predicted_labels == test_y).sum().item() / len(test_y)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    test_loss = los(predictions, test_y)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ce45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9705, 27)\n",
      "(9705,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sleep_light</th>\n",
       "      <th>sleep_score_latency</th>\n",
       "      <th>sleep_midpoint_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>sleep_onset_latency</th>\n",
       "      <th>sleep_restless</th>\n",
       "      <th>sleep_score_alignment</th>\n",
       "      <th>sleep_total</th>\n",
       "      <th>sleep_score_deep</th>\n",
       "      <th>sleep_awake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11670</td>\n",
       "      <td>94</td>\n",
       "      <td>12390</td>\n",
       "      <td>24480</td>\n",
       "      <td>990</td>\n",
       "      <td>32</td>\n",
       "      <td>99</td>\n",
       "      <td>22620</td>\n",
       "      <td>92</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11250</td>\n",
       "      <td>99</td>\n",
       "      <td>15750</td>\n",
       "      <td>31200</td>\n",
       "      <td>900</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>29340</td>\n",
       "      <td>100</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14100</td>\n",
       "      <td>97</td>\n",
       "      <td>15270</td>\n",
       "      <td>30420</td>\n",
       "      <td>840</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>27210</td>\n",
       "      <td>97</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15750</td>\n",
       "      <td>91</td>\n",
       "      <td>14520</td>\n",
       "      <td>28980</td>\n",
       "      <td>690</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>27090</td>\n",
       "      <td>96</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18600</td>\n",
       "      <td>72</td>\n",
       "      <td>14940</td>\n",
       "      <td>30180</td>\n",
       "      <td>300</td>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>28980</td>\n",
       "      <td>81</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>20580</td>\n",
       "      <td>94</td>\n",
       "      <td>23640</td>\n",
       "      <td>46200</td>\n",
       "      <td>780</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>36720</td>\n",
       "      <td>75</td>\n",
       "      <td>9480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>18030</td>\n",
       "      <td>99</td>\n",
       "      <td>20340</td>\n",
       "      <td>38280</td>\n",
       "      <td>900</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "      <td>30000</td>\n",
       "      <td>70</td>\n",
       "      <td>8280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>13470</td>\n",
       "      <td>72</td>\n",
       "      <td>13350</td>\n",
       "      <td>26940</td>\n",
       "      <td>300</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>24360</td>\n",
       "      <td>95</td>\n",
       "      <td>2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9703</th>\n",
       "      <td>18420</td>\n",
       "      <td>97</td>\n",
       "      <td>19620</td>\n",
       "      <td>40860</td>\n",
       "      <td>930</td>\n",
       "      <td>39</td>\n",
       "      <td>100</td>\n",
       "      <td>31920</td>\n",
       "      <td>91</td>\n",
       "      <td>8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>16470</td>\n",
       "      <td>99</td>\n",
       "      <td>18330</td>\n",
       "      <td>36720</td>\n",
       "      <td>900</td>\n",
       "      <td>36</td>\n",
       "      <td>97</td>\n",
       "      <td>27870</td>\n",
       "      <td>93</td>\n",
       "      <td>8850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9705 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sleep_light  sleep_score_latency  sleep_midpoint_time  sleep_duration  \\\n",
       "0           11670                   94                12390           24480   \n",
       "1           11250                   99                15750           31200   \n",
       "2           14100                   97                15270           30420   \n",
       "3           15750                   91                14520           28980   \n",
       "4           18600                   72                14940           30180   \n",
       "...           ...                  ...                  ...             ...   \n",
       "9700        20580                   94                23640           46200   \n",
       "9701        18030                   99                20340           38280   \n",
       "9702        13470                   72                13350           26940   \n",
       "9703        18420                   97                19620           40860   \n",
       "9704        16470                   99                18330           36720   \n",
       "\n",
       "      sleep_onset_latency  sleep_restless  sleep_score_alignment  sleep_total  \\\n",
       "0                     990              32                     99        22620   \n",
       "1                     900              22                    100        29340   \n",
       "2                     840              31                    100        27210   \n",
       "3                     690              32                    100        27090   \n",
       "4                     300              33                    100        28980   \n",
       "...                   ...             ...                    ...          ...   \n",
       "9700                  780              42                    100        36720   \n",
       "9701                  900              35                    100        30000   \n",
       "9702                  300              42                    100        24360   \n",
       "9703                  930              39                    100        31920   \n",
       "9704                  900              36                     97        27870   \n",
       "\n",
       "      sleep_score_deep  sleep_awake  \n",
       "0                   92         1860  \n",
       "1                  100         1860  \n",
       "2                   97         3210  \n",
       "3                   96         1890  \n",
       "4                   81         1200  \n",
       "...                ...          ...  \n",
       "9700                75         9480  \n",
       "9701                70         8280  \n",
       "9702                95         2580  \n",
       "9703                91         8940  \n",
       "9704                93         8850  \n",
       "\n",
       "[9705 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = train_all\n",
    "X_all.drop(columns=['number'], inplace=True)\n",
    "X_all_target = X_all['target']\n",
    "X_all.drop(columns=['target'], inplace=True)\n",
    "\n",
    "print(X_all.values.shape)\n",
    "print(X_all_target.shape)\n",
    "\n",
    "data_for_logit_all = X_all[feature].copy()\n",
    "data_for_logit_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50b55d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler_all = MinMaxScaler()\n",
    "X_all_scaled = scaler_all.fit_transform(data_for_logit_all)\n",
    "\n",
    "x = torch.tensor(X_all_scaled).float()\n",
    "y = torch.tensor(X_all_target.values-1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b66f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1 avg loss; 0.0182\n",
      "        acc.;    0.8697\n",
      "epoch   2 avg loss; 0.0223\n",
      "        acc.;    0.7733\n",
      "epoch   3 avg loss; 0.0276\n",
      "        acc.;    0.6757\n",
      "epoch   4 avg loss; 0.0271\n",
      "        acc.;    0.6615\n",
      "epoch   5 avg loss; 0.0293\n",
      "        acc.;    0.6284\n",
      "epoch   6 avg loss; 0.0289\n",
      "        acc.;    0.6496\n",
      "epoch   7 avg loss; 0.0267\n",
      "        acc.;    0.6904\n",
      "epoch   8 avg loss; 0.0264\n",
      "        acc.;    0.6752\n",
      "epoch   9 avg loss; 0.0269\n",
      "        acc.;    0.6537\n",
      "epoch  10 avg loss; 0.0289\n",
      "        acc.;    0.6482\n",
      "epoch  11 avg loss; 0.0286\n",
      "        acc.;    0.6252\n",
      "epoch  12 avg loss; 0.0293\n",
      "        acc.;    0.6087\n",
      "epoch  13 avg loss; 0.0274\n",
      "        acc.;    0.6730\n",
      "epoch  14 avg loss; 0.0288\n",
      "        acc.;    0.6640\n",
      "epoch  15 avg loss; 0.0272\n",
      "        acc.;    0.6437\n",
      "epoch  16 avg loss; 0.0295\n",
      "        acc.;    0.6044\n",
      "epoch  17 avg loss; 0.0291\n",
      "        acc.;    0.5669\n",
      "epoch  18 avg loss; 0.0331\n",
      "        acc.;    0.5184\n",
      "epoch  19 avg loss; 0.0315\n",
      "        acc.;    0.5465\n",
      "epoch  20 avg loss; 0.0290\n",
      "        acc.;    0.5170\n",
      "done\n",
      "Final accuracy: 0.3519\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    " \n",
    "bs = 32\n",
    "epoch = 20\n",
    "\n",
    "for e in range(1,epoch + 1):\n",
    "    eloss = defaultdict(lambda: [])\n",
    "    for idx in range(0,len(x),bs):\n",
    "        opt.zero_grad()\n",
    "        p = net(x[idx:idx+bs])\n",
    "        loss = los(p, y[idx:idx+bs])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # keep track of some summary statistics\n",
    "        eloss['loss'].append(loss.item())\n",
    "        eloss['n'].append(x[idx:idx+bs].size(0))\n",
    "        eloss['corr'].append(sum(p.max(axis=1)[1] == y[idx:idx+bs]))\n",
    "    print(f'epoch {e:3d} avg loss; {sum(eloss[\"loss\"])/sum(eloss[\"n\"]):.4f}')\n",
    "    print(f'        acc.;    {sum(eloss[\"corr\"])/sum(eloss[\"n\"]):.4f}')\n",
    "print(\"done\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    final_accuracy = (net(x).argmax(dim=1) == y).sum().item() / len(y)\n",
    "print(f\"Final accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b65bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1212\n",
      "Test Loss: 1.1011\n"
     ]
    }
   ],
   "source": [
    "test_all, test_mean = preprocessing(test, test_label)\n",
    "\n",
    "test_all_target = test_all['target']\n",
    "\n",
    "X_test_all = test_all[feature].copy()\n",
    "\n",
    "test_X_all_scaled = scaler_all.transform(X_test_all)\n",
    "test_x_all = torch.tensor(test_X_all_scaled).float()\n",
    "test_y_all = torch.tensor(test_all_target.values - 1).long()\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = net(test_x_all)\n",
    "    predicted_labels = predictions.max(dim=1)[1]\n",
    "    \n",
    "    accuracy = (predicted_labels == test_y_all).sum().item() / len(test_y_all)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    test_loss = los(predictions, test_y_all)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3934d5e3",
   "metadata": {},
   "source": [
    "성능 향상을 위한 데이터 처리\n",
    "\n",
    "-> (1) 데이터 불균형 처리\n",
    "(2) scailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "609d2134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9705, 10)\n",
      "(9705,)\n",
      "(33, 10)\n"
     ]
    }
   ],
   "source": [
    "print(data_for_logit_all.shape)\n",
    "print(X_all_target.shape)\n",
    "print(X_test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a9f0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERSAMPLING 적용 후 x train dataset: (12108, 10)\n",
      "UNDERSAMPLING 적용 후 x train dataset: (1254, 10)\n"
     ]
    }
   ],
   "source": [
    "# OVERSAMPLING\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 가져오기\n",
    "# crossentropyloss를 적용하기 위해서는 label이 0부터 시작해야함\n",
    "# 현재 target의 label은 1, 2, 3이기 때문에 변환을 해줌.\n",
    "X = data_for_logit_all.values\n",
    "y = X_all_target.values - 1\n",
    "\n",
    "# train, validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# OVERSAMPLING 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over= smote.fit_resample(X_train, y_train)\n",
    "print(f'OVERSAMPLING 적용 후 x train dataset: {X_train_over.shape}')\n",
    "\n",
    "# UNDERSAMPLING 적용\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train, y_train)\n",
    "print(f'UNDERSAMPLING 적용 후 x train dataset: {X_train_under.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ca683e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    418\n",
       "1    418\n",
       "2    418\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train_under).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\datamining\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Train loss: 89.2013 | Train Accuracy: 0.7013\n",
      "          | Validation loss: 1.1900 | Validation Accuracy: 0.0525\n",
      "Epoch   2 | Train loss: 564.4540 | Train Accuracy: 0.6868\n",
      "          | Validation loss: 1.2176 | Validation Accuracy: 0.0525\n",
      "Epoch   3 | Train loss: 799.3688 | Train Accuracy: 0.6818\n",
      "          | Validation loss: 1.1686 | Validation Accuracy: 0.0525\n",
      "Epoch   4 | Train loss: 564.7536 | Train Accuracy: 0.6867\n",
      "          | Validation loss: 1.1326 | Validation Accuracy: 0.0570\n",
      "Epoch   5 | Train loss: 291.7280 | Train Accuracy: 0.6914\n",
      "          | Validation loss: 1.1214 | Validation Accuracy: 0.0659\n",
      "Epoch   6 | Train loss: 277.6242 | Train Accuracy: 0.6895\n",
      "          | Validation loss: 1.1137 | Validation Accuracy: 0.1233\n",
      "Epoch   7 | Train loss: 230.7365 | Train Accuracy: 0.6794\n",
      "          | Validation loss: 1.1167 | Validation Accuracy: 0.1150\n",
      "Epoch   8 | Train loss: 241.7699 | Train Accuracy: 0.6771\n",
      "          | Validation loss: 1.0976 | Validation Accuracy: 0.3963\n",
      "Epoch   9 | Train loss: 162.0142 | Train Accuracy: 0.6835\n",
      "          | Validation loss: 1.0964 | Validation Accuracy: 0.3898\n",
      "Epoch  10 | Train loss: 133.7746 | Train Accuracy: 0.6858\n",
      "          | Validation loss: 1.0919 | Validation Accuracy: 0.3802\n",
      "Epoch  11 | Train loss: 74.1298 | Train Accuracy: 0.6881\n",
      "          | Validation loss: 1.0867 | Validation Accuracy: 0.3922\n",
      "Epoch  12 | Train loss: 87.3033 | Train Accuracy: 0.6817\n",
      "          | Validation loss: 1.0829 | Validation Accuracy: 0.3922\n",
      "Epoch  13 | Train loss: 57.7517 | Train Accuracy: 0.6874\n",
      "          | Validation loss: 1.0764 | Validation Accuracy: 0.4289\n",
      "Epoch  14 | Train loss: 42.7857 | Train Accuracy: 0.6898\n",
      "          | Validation loss: 1.0731 | Validation Accuracy: 0.4633\n",
      "Epoch  15 | Train loss: 38.7544 | Train Accuracy: 0.6989\n",
      "          | Validation loss: 1.0661 | Validation Accuracy: 0.5979\n",
      "Epoch  16 | Train loss: 28.3347 | Train Accuracy: 0.6904\n",
      "          | Validation loss: 1.0640 | Validation Accuracy: 0.5992\n",
      "Epoch  17 | Train loss: 31.2349 | Train Accuracy: 0.6938\n",
      "          | Validation loss: 1.0590 | Validation Accuracy: 0.5992\n",
      "Epoch  18 | Train loss: 22.7255 | Train Accuracy: 0.6937\n",
      "          | Validation loss: 1.0540 | Validation Accuracy: 0.5992\n",
      "Epoch  19 | Train loss: 20.7820 | Train Accuracy: 0.6945\n",
      "          | Validation loss: 1.0474 | Validation Accuracy: 0.5992\n",
      "Epoch  20 | Train loss: 21.5257 | Train Accuracy: 0.6971\n",
      "          | Validation loss: 1.0459 | Validation Accuracy: 0.5992\n",
      "done\n",
      "Final Training Accuracy: 0.3346\n",
      "Test Accuracy: 0.7879\n",
      "Test Loss: 1.0323\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 - OVERSAMPLING\n",
    "\n",
    "scaler_over = MinMaxScaler()\n",
    "X_train = scaler_over.fit_transform(X_train_over)\n",
    "X_val = scaler_over.transform(X_val)\n",
    "test_x_all = torch.tensor(scaler_over.transform(X_test_all)).float()\n",
    "\n",
    "X_train = torch.tensor(X_train_over).float()\n",
    "y_train = torch.tensor(y_train_over).long()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "y_val = torch.tensor(y_val).long()\n",
    "\n",
    "\n",
    "net_over = DementiaNet()\n",
    "opt_over = torch.optim.Adam(net_over.parameters(), lr=1e-3)\n",
    "los_over = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_over = 64\n",
    "epoch = 20\n",
    "\n",
    "for e in range(1,epoch + 1):\n",
    "    eloss = defaultdict(lambda: [])\n",
    "    net_over.train()\n",
    "    for idx in range(0,len(X_train),batch_over):\n",
    "        opt_over.zero_grad()\n",
    "        p = net_over(X_train[idx:idx + batch_over])\n",
    "        loss = los_over(p, y_train[idx:idx + batch_over])\n",
    "        loss.backward()\n",
    "        opt_over.step()\n",
    "        # keep track of some summary statistics\n",
    "        eloss['loss'].append(loss.item())\n",
    "        eloss['n'].append(X_train[idx:idx+batch_over].size(0))\n",
    "        eloss['corr'].append(sum(p.max(axis=1)[1] == y_train[idx:idx + batch_over]))\n",
    "    train_loss = sum(eloss[\"loss\"]) / len(eloss[\"n\"])\n",
    "    train_acc = sum(eloss[\"corr\"]) / sum(eloss[\"n\"])\n",
    "    print(f'Epoch {e:3d} | Train loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}')\n",
    "    \n",
    "    net_over.eval()\n",
    "    with torch.no_grad():\n",
    "        p_val = net_over(X_val)\n",
    "        val_loss = los_over(p_val, y_val).item()\n",
    "        val_acc = (p_val.argmax(dim=1) == y_val).sum().item() / len(y_val)\n",
    "    print(f'          | Validation loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.4f}')\n",
    "        \n",
    "print(\"done\")\n",
    "\n",
    "net_over.eval()\n",
    "with torch.no_grad():\n",
    "    final_accuracy = (net_over(X_train).argmax(dim=1) == y_train).sum().item() / len(y_train)\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "net_over.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = net_over(test_x_all)\n",
    "    predicted_labels = predictions.max(dim=1)[1]\n",
    "    \n",
    "    accuracy = (predicted_labels == test_y_all).sum().item() / len(test_y_all)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    test_loss = los_over(predictions, test_y_all)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e615dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\datamining\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\zz325\\AppData\\Local\\Temp\\ipykernel_10152\\4190510000.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val = torch.tensor(y_val).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Train loss: 938.5504 | Train Accuracy: 0.8884\n",
      "          | Validation loss: 1.2613 | Validation Accuracy: 0.0525\n",
      "Epoch   2 | Train loss: 4839.4003 | Train Accuracy: 0.7089\n",
      "          | Validation loss: 1.2001 | Validation Accuracy: 0.0525\n",
      "Epoch   3 | Train loss: 1860.0803 | Train Accuracy: 0.6954\n",
      "          | Validation loss: 1.1855 | Validation Accuracy: 0.0525\n",
      "Epoch   4 | Train loss: 915.4622 | Train Accuracy: 0.6874\n",
      "          | Validation loss: 1.1694 | Validation Accuracy: 0.0525\n",
      "Epoch   5 | Train loss: 424.1191 | Train Accuracy: 0.6914\n",
      "          | Validation loss: 1.1588 | Validation Accuracy: 0.0525\n",
      "Epoch   6 | Train loss: 318.1759 | Train Accuracy: 0.7129\n",
      "          | Validation loss: 1.1525 | Validation Accuracy: 0.0525\n",
      "Epoch   7 | Train loss: 126.4437 | Train Accuracy: 0.6866\n",
      "          | Validation loss: 1.1485 | Validation Accuracy: 0.0525\n",
      "Epoch   8 | Train loss: 59.3321 | Train Accuracy: 0.6762\n",
      "          | Validation loss: 1.1394 | Validation Accuracy: 0.0525\n",
      "Epoch   9 | Train loss: 29.9717 | Train Accuracy: 0.6284\n",
      "          | Validation loss: 1.1338 | Validation Accuracy: 0.0525\n",
      "Epoch  10 | Train loss: 12.6382 | Train Accuracy: 0.5598\n",
      "          | Validation loss: 1.1310 | Validation Accuracy: 0.0525\n",
      "Epoch  11 | Train loss: 5.7263 | Train Accuracy: 0.4912\n",
      "          | Validation loss: 1.1298 | Validation Accuracy: 0.3482\n",
      "Epoch  12 | Train loss: 3.2048 | Train Accuracy: 0.5327\n",
      "          | Validation loss: 1.1332 | Validation Accuracy: 0.3482\n",
      "Epoch  13 | Train loss: 2.2320 | Train Accuracy: 0.4785\n",
      "          | Validation loss: 1.1365 | Validation Accuracy: 0.3482\n",
      "Epoch  14 | Train loss: 2.1737 | Train Accuracy: 0.4880\n",
      "          | Validation loss: 1.1346 | Validation Accuracy: 0.3482\n",
      "Epoch  15 | Train loss: 1.7262 | Train Accuracy: 0.4809\n",
      "          | Validation loss: 1.1362 | Validation Accuracy: 0.3482\n",
      "Epoch  16 | Train loss: 1.5836 | Train Accuracy: 0.4793\n",
      "          | Validation loss: 1.1376 | Validation Accuracy: 0.3482\n",
      "Epoch  17 | Train loss: 1.4650 | Train Accuracy: 0.4761\n",
      "          | Validation loss: 1.1381 | Validation Accuracy: 0.3482\n",
      "Epoch  18 | Train loss: 1.3785 | Train Accuracy: 0.4673\n",
      "          | Validation loss: 1.1390 | Validation Accuracy: 0.3482\n",
      "Epoch  19 | Train loss: 1.2925 | Train Accuracy: 0.4625\n",
      "          | Validation loss: 1.1389 | Validation Accuracy: 0.3482\n",
      "Epoch  20 | Train loss: 1.2345 | Train Accuracy: 0.4585\n",
      "          | Validation loss: 1.1398 | Validation Accuracy: 0.3482\n",
      "done\n",
      "Final Training Accuracy: 0.4306\n",
      "Test Accuracy: 0.1212\n",
      "Test Loss: 1.1283\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 - UNDERSAMPLING\n",
    "scaler_under = MinMaxScaler()\n",
    "X_train = scaler_under.fit_transform(X_train_under)\n",
    "X_val = scaler_under.transform(X_val)\n",
    "test_x_all = torch.tensor(scaler_under.transform(X_test_all)).float()\n",
    "\n",
    "X_train = torch.tensor(X_train_under).float()\n",
    "y_train = torch.tensor(y_train_under).long()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "y_val = torch.tensor(y_val).long()\n",
    "\n",
    "net_under = DementiaNet()\n",
    "opt_under = torch.optim.Adam(net_under.parameters(), lr=1e-3)\n",
    "los_under = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_under = 8\n",
    "epoch_under = 20\n",
    "\n",
    "for e in range(1,epoch_under + 1):\n",
    "    eloss = defaultdict(lambda: [])\n",
    "    net_under.train()\n",
    "    for idx in range(0,len(X_train),batch_under):\n",
    "        opt_under.zero_grad()\n",
    "        p = net_under(X_train[idx:idx + batch_under])\n",
    "        loss = los_under(p, y_train[idx:idx + batch_under])\n",
    "        loss.backward()\n",
    "        opt_under.step()\n",
    "        # keep track of some summary statistics\n",
    "        eloss['loss'].append(loss.item())\n",
    "        eloss['n'].append(X_train[idx:idx+batch_under].size(0))\n",
    "        eloss['corr'].append(sum(p.max(axis=1)[1] == y_train[idx:idx + batch_under]))\n",
    "    train_loss = sum(eloss[\"loss\"]) / len(eloss[\"n\"])\n",
    "    train_acc = sum(eloss[\"corr\"]) / sum(eloss[\"n\"])\n",
    "    print(f'Epoch {e:3d} | Train loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}')\n",
    "    \n",
    "    net_under.eval()\n",
    "    with torch.no_grad():\n",
    "        p_val = net_under(X_val)\n",
    "        val_loss = los_under(p_val, y_val).item()\n",
    "        val_acc = (p_val.argmax(dim=1) == y_val).sum().item() / len(y_val)\n",
    "    print(f'          | Validation loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.4f}')\n",
    "        \n",
    "print(\"done\")\n",
    "\n",
    "net_under.eval()\n",
    "with torch.no_grad():\n",
    "    final_accuracy = (net_under(X_train).argmax(dim=1) == y_train).sum().item() / len(y_train)\n",
    "print(f\"Final Training Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "net_under.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = net_under(test_x_all)\n",
    "    predicted_labels = predictions.max(dim=1)[1]\n",
    "    \n",
    "    accuracy = (predicted_labels == test_y_all).sum().item() / len(test_y_all)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    test_loss = los_under(predictions, test_y_all)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0d8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
